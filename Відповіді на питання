1. У першій частині ми отримали 5 Jobs, тому що:
Кожна дія (Action) або операція, яка вимагає пересилання даних між вузлами (Shuffle), створює новий Job.
У коді є лише один Action (collect()), який запускає обчислення всіх попередніх трансформацій.
Spark виконує такі етапи:
Завантаження CSV-файлу (read.csv) — 1-й Job.
Репартиціювання даних (repartition(2)) — 2-й Job.
Фільтрація даних (where("final_priority < 3")) — 3-й Job.
Агрегація даних (groupBy("unit_id").count()) — 4-й Job.
Останнє фільтрування (where("count > 2")) — 5-й Job.

****************************************************************

2. У другій частині з'явилося додаткових 3 Jobs, тому що було додано другий Action (collect()):
Перший collect() виконав усі попередні трансформації до цього моменту.
Другий collect() повторно виконав ті самі обчислення, оскільки Spark не кешує дані автоматично.
Кожен Action (collect()) змушує Spark обчислювати всі попередні трансформації заново, якщо дані не були кешовані.

****************************************************************

3. Функція cache() зберігає проміжний результат у пам'яті, тому повторне використання тих самих даних не вимагає їх повторного обчислення.
Без кешування Spark виконує ті самі обчислення кожного разу, коли викликається Action (collect()), що призводить до додаткових Jobs.
Використання cache() дозволило Spark уникнути повторного виконання операцій Shuffle та обчислень, зменшивши кількість Jobs до семи.

****************************************************************

